{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KRUTHIKA2405/Green-AI/blob/main/Forest_Fire_Detection_Using_Satellite_Imagery.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f41930a",
      "metadata": {
        "id": "9f41930a"
      },
      "source": [
        "<h1 style=\"text-align: center;\">Forest Fire Detection using Computer Vision</h1>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28b679ef",
      "metadata": {
        "id": "28b679ef"
      },
      "source": [
        "![forest%20fire%20cover%20image.png](attachment:forest%20fire%20cover%20image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04287279",
      "metadata": {
        "id": "04287279"
      },
      "source": [
        "## 1. Problem Statement\n",
        "\n",
        "Imagine you are in charge of watching a big forest. You want to keep everyone safe, but sometimes wildfires can start without warning. These fires can spread quickly and cause a lot of damage. So, we want to build a computer program that can look at pictures of forests and tell us if there’s a fire starting or not. This program can help people react faster to stop wildfires!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13fa4626",
      "metadata": {
        "id": "13fa4626"
      },
      "source": [
        "## 2. Objectives\n",
        "\n",
        "This project will:\n",
        "\n",
        "    Teach the computer to recognize pictures with wildfires and without wildfires.\n",
        "    Build a model (a smart program) that looks at forest pictures and decides if there’s a fire.\n",
        "    Show us a simple screen (a GUI) where we can upload forest pictures and get quick answers on fire danger.\n",
        "    Help keep forests and people safe by giving early warnings about fires."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3443b2bc",
      "metadata": {
        "id": "3443b2bc"
      },
      "source": [
        "### 3. Dataset Information\n",
        "\n",
        "To teach the computer about wildfires, we’ll use a special set of pictures called a dataset. This dataset has pictures of forests divided into two types: with a fire (wildfire) and without a fire (no wildfire). These images help the computer learn to tell the difference.\n",
        "\n",
        "    Where to Get the Dataset: You can download the dataset from Kaggle\n",
        "    https://www.kaggle.com/datasets/abdelghaniaaba/wildfire-prediction-dataset\n",
        "    Dataset Folders:\n",
        "        Inside, there are three main folders: train, test, and valid.\n",
        "        Each folder has two subfolders:\n",
        "            Wildfire: Contains pictures showing wildfires in forests.\n",
        "            NoWildfire: Contains pictures showing forests without any fire."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1330f060",
      "metadata": {
        "id": "1330f060"
      },
      "source": [
        "## 4. Understanding the CNN Model\n",
        "\n",
        "CNN stands for Convolutional Neural Network. It’s a special type of program that can look at pictures and learn to find important details. Imagine how you look at a picture and notice trees, animals, or fire — CNN does something similar!\n",
        "\n",
        "Here’s how it works, step-by-step:\n",
        "\n",
        "    Looking at Patterns: The CNN looks at lots of tiny patterns in pictures, like shapes and colors.\n",
        "    Learning from Examples: It looks at many images of wildfires and no wildfires to learn what makes them different.\n",
        "    Making Predictions: Once trained, the CNN can look at a new picture and guess if it shows a fire or not."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b14009e0",
      "metadata": {
        "id": "b14009e0"
      },
      "source": [
        "## 5. Code Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0197198d",
      "metadata": {
        "id": "0197198d"
      },
      "source": [
        "### Step 1: Importing Libraries\n",
        "\n",
        "We’ll use Python with TensorFlow/Keras for the CNN model and Tkinter for the GUI. Make sure you have these libraries installed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0c2cd988",
      "metadata": {
        "id": "0c2cd988"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator #for data augumentation\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "import tkinter as tk\n",
        "from tkinter import filedialog #provides a dialog box to select files.\n",
        "from PIL import Image, ImageTk #ImageTk - Converts images for display in Tkinter GUIs\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "007f275d",
      "metadata": {
        "id": "007f275d"
      },
      "source": [
        "### Step 2: Loading and Preprocessing the Data\n",
        "\n",
        "We'll use ImageDataGenerator to load images from your dataset's train, valid, and test folders. This will resize and normalize images so our model can use them."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " Set up directories\n",
        "train_dir = r\"train\"\n",
        "valid_dir = r\"valid\"\n",
        "test_dir = r\"test\"\n",
        "\n",
        "# Set up ImageDataGenerators for loading images\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Load images from directories\n",
        "train_generator = TRAIN_datagen.flow_from_directory(train_dir, target_size=(64, 64), batch_size=32, class_mode='binary')\n",
        "valid_generator = VALID_datagen.flow_from_directory(valid_dir, target_size=(64, 64), batch_size=32, class_mode='binary')\n",
        "test_generator = TEST_datagen.flow_from_directory(test_dir, target_size=(64, 64), batch_size=32, class_mode='binary')"
      ],
      "metadata": {
        "id": "Xb6IaUsyrTR-"
      },
      "id": "Xb6IaUsyrTR-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define data augmentation for training data\n",
        "TRAIN_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255.0,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Define data augmentation for validation and test data\n",
        "VALID_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "TEST_datagen = ImageDataGenerator(rescale=1.0/255.0)\n"
      ],
      "metadata": {
        "id": "8JjvE0bjmXlW"
      },
      "id": "8JjvE0bjmXlW",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "d0a2ade6",
      "metadata": {
        "id": "d0a2ade6"
      },
      "source": [
        "### Step 3: Building the CNN Model\n",
        "\n",
        "The CNN model will have multiple convolutional layers to extract features, followed by dense layers for classification.\n",
        "- Sequential: When you need a simple feed-forward model with a single input and output.\n",
        "- Functional: When your model has multiple inputs/outputs or non-linear architectures.\n",
        "- Subclassing: When custom forward logic is required or your model's architecture cannot be easily represented using pre-defined layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d769b3c",
      "metadata": {
        "id": "6d769b3c"
      },
      "outputs": [],
      "source": [
        "# Building a simple CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')  # Binary classification: wildfire or no wildfire\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2782056",
      "metadata": {
        "id": "d2782056"
      },
      "source": [
        "We noticed some images in our dataset are incomplete or corrupted, causing TensorFlow to fail when trying to load them.\n",
        "Here are a few steps to handle this issue:\n",
        "\n",
        "Solution: Skip Corrupted Images\n",
        "\n",
        "One way to handle this is to modify the data loading process to skip over corrupted images.\n",
        "\n",
        "    Re-import the PIL library with a setting that will ignore truncated images.\n",
        "\n",
        "    We add this line at the beginning of your script."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ba1f311",
      "metadata": {
        "id": "3ba1f311"
      },
      "outputs": [],
      "source": [
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a847ddcb",
      "metadata": {
        "id": "a847ddcb"
      },
      "source": [
        "### Step 4: Training the Model\n",
        "\n",
        "Train the model with the train and valid data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a516875b",
      "metadata": {
        "id": "a516875b"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "history = model.fit(train_generator, validation_data=valid_generator, epochs=10, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c82c734-25c3-4232-9098-7c3239d22231",
      "metadata": {
        "id": "9c82c734-25c3-4232-9098-7c3239d22231"
      },
      "outputs": [],
      "source": [
        "#save the model\n",
        "model.save(\"ffd_model.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3394796",
      "metadata": {
        "id": "d3394796"
      },
      "source": [
        "### Step 5: Building the GUI with Tkinter\n",
        "\n",
        "Now, let’s create a GUI that lets us upload an image and predict if there’s a wildfire."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d2aca8d-6eb3-4747-90d2-777721276ecf",
      "metadata": {
        "id": "6d2aca8d-6eb3-4747-90d2-777721276ecf"
      },
      "outputs": [],
      "source": [
        "import tkinter as tk\n",
        "from tkinter import filedialog\n",
        "\n",
        "from PIL import Image, ImageTk\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c13f17c4-32cc-4576-8a07-644adbbba5d8",
      "metadata": {
        "id": "c13f17c4-32cc-4576-8a07-644adbbba5d8"
      },
      "outputs": [],
      "source": [
        "# Load the model\n",
        "model = load_model(\"ffd_model.h5\")\n",
        "print(\"Model loaded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae03e0b9",
      "metadata": {
        "id": "ae03e0b9"
      },
      "outputs": [],
      "source": [
        "# Function to load and predict an image\n",
        "def predict_image():\n",
        "    # Open file dialog to select an image\n",
        "    file_path = filedialog.askopenfilename()\n",
        "    if file_path:\n",
        "        # Display the image in the GUI\n",
        "        img = Image.open(file_path)\n",
        "        img = img.resize((200, 200))\n",
        "        img = ImageTk.PhotoImage(img)    #convert image for tk\n",
        "        image_label.configure(image=img) #update the image in GUI\n",
        "        image_label.image = img\n",
        "\n",
        "        # Preprocess the image for the model\n",
        "        img_for_model = Image.open(file_path).resize((64, 64))\n",
        "        img_array = np.array(img_for_model) / 255.0  # Rescale like during training\n",
        "        img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "\n",
        "        # Make a prediction\n",
        "        prediction = model.predict(img_array)[0][0] #extracts the scalar prediction value\n",
        "        result = \"Wildfire\" if prediction > 0.5 else \"No Wildfire\"\n",
        "        result_label.config(text=\"Prediction: \" + result)\n",
        "\n",
        "# Setting up the GUI window\n",
        "root = tk.Tk()\n",
        "root.title(\"Forest Fire Detection\")\n",
        "root.geometry(\"400x400\")\n",
        "\n",
        "# Add widgets\n",
        "btn = tk.Button(root, text=\"Upload Image\", command=predict_image) #button triggers the predict_image() function when clicked\n",
        "btn.pack(pady=20)\n",
        "\n",
        "#Placeholder for displaying the selected image\n",
        "image_label = tk.Label(root)\n",
        "image_label.pack()\n",
        "\n",
        "#Label to display the prediction result\n",
        "result_label = tk.Label(root, text=\"Prediction: \", font=(\"Helvetica\", 16))\n",
        "result_label.pack(pady=20)\n",
        "\n",
        "#Starts the Tkinter event loop, keeping the GUI active until manually closed\n",
        "root.mainloop()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7b96278",
      "metadata": {
        "id": "a7b96278"
      },
      "source": [
        "### Step 6: Testing the Model\n",
        "\n",
        "You can now use the GUI to test the model. Click \"Upload Image,\" select an image, and the GUI will display the image and predict if it shows a wildfire or not."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfa10436",
      "metadata": {
        "id": "dfa10436"
      },
      "source": [
        "## 5. Conclusion\n",
        "\n",
        "With this project, we have created a simple computer program that helps spot wildfires early by looking at pictures of forests. This project shows how computer vision, a field that teaches computers to see and understand images, can help us make safer decisions for people and nature. Using CNN, we taught the computer to recognize fires, giving us a way to respond faster and prevent fires from spreading."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc543dd1",
      "metadata": {
        "id": "fc543dd1"
      },
      "source": [
        "![forest%20fire%20image.png](attachment:forest%20fire%20image.png)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}